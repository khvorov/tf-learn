{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import urllib.request\n",
    "import ptb_iterator as reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data lenght: 985129 bytes\n"
     ]
    }
   ],
   "source": [
    "# load and process data\n",
    "\n",
    "# file_url = 'https://raw.githubusercontent.com/jcjohnson/torch-rnn/master/data/tiny-shakespeare.txt'\n",
    "# file_name = 'tinyshakespeare.txt'\n",
    "\n",
    "# if not os.path.exists(file_name):\n",
    "#     urllib.request.urlretrieve(file_url, file_name)\n",
    "file_name = 'majakovski.txt'\n",
    "\n",
    "with open(file_name, 'r') as f:\n",
    "    raw_data = f.read()\n",
    "    print('Data lenght: {} bytes'.format(len(raw_data)))\n",
    "\n",
    "vocab = set(raw_data)\n",
    "vocab_size = len(vocab)\n",
    "idx_to_vocab = dict(enumerate(vocab))\n",
    "vocab_to_idx = dict(zip(idx_to_vocab.values(), idx_to_vocab.keys()))\n",
    "\n",
    "data = [vocab_to_idx[c] for c in raw_data]\n",
    "del raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility functions\n",
    "\n",
    "def gen_epochs(n, num_steps, batch_size):\n",
    "    for i in range(n):\n",
    "        yield reader.ptb_iterator(data, batch_size, num_steps)\n",
    "\n",
    "def reset_graph():\n",
    "    if 'sess' in globals() and sess:\n",
    "        sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "def restore_or_initialize_session(session, saver, checkpoint):\n",
    "    if isinstance(checkpoint, str):\n",
    "        try:\n",
    "            saver.restore(session, checkpoint)\n",
    "            return\n",
    "        except:\n",
    "            print('Failed to restore from checkpoint: {}, initializing variables instead'.format(checkpoint))\n",
    "    \n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "def train_network(g, num_epochs, num_steps = 200, batch_size = 32, verbose = True, save = False):\n",
    "    tf.set_random_seed(2345)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # try to restore the graph\n",
    "        restore_or_initialize_session(sess, g['saver'], save)\n",
    "        training_losses = []\n",
    "        \n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps, batch_size)):\n",
    "            training_loss = 0\n",
    "            steps = 0\n",
    "            training_state = None\n",
    "            \n",
    "            for X, Y in epoch:\n",
    "                # workaround to avoid mis-shaped inputs\n",
    "                if X.shape[1] != num_steps or Y.shape[1] != num_steps:\n",
    "                    continue\n",
    "                steps += 1\n",
    "                feed_dict = {g['x']: X, g['y']: Y}\n",
    "                if training_state is not None:\n",
    "                    feed_dict[g['init_state']] = training_state\n",
    "                training_loss_, training_state, _ = \\\n",
    "                    sess.run([g['total_loss'], g['final_state'], g['train_step']], feed_dict)\n",
    "                training_loss += training_loss_\n",
    "\n",
    "            if verbose:\n",
    "                print('avg training loss for epoch {0}: {1:.4f}'.format(idx, training_loss/steps))\n",
    "            \n",
    "            training_losses.append(training_loss/steps)\n",
    "        \n",
    "        # I hate dynamic typing....\n",
    "        if isinstance(save, str):\n",
    "            g['saver'].save(sess, save)\n",
    "\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_multilayer_lstm_graph_with_dynamic_rnn(\n",
    "        state_size=100, num_classes=vocab_size, batch_size=32,\n",
    "        num_steps=200, num_layers=3, learning_rate=1e-4):\n",
    "    reset_graph()\n",
    "    \n",
    "    x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "    y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "\n",
    "    embeddings = tf.get_variable('embedding_matrix', [num_classes, state_size])\n",
    "    \n",
    "    # our inputs now is a tensor of dims batch_size x num_steps x state_size\n",
    "    rnn_inputs = tf.nn.embedding_lookup(embeddings, x)\n",
    "    \n",
    "    lstm_cells = [tf.contrib.rnn.LSTMCell(state_size, state_is_tuple=True) for _ in range(num_layers)]\n",
    "    cell = tf.contrib.rnn.MultiRNNCell(lstm_cells, state_is_tuple=True)\n",
    "    init_state = cell.zero_state(batch_size, tf.float32)\n",
    "    rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, rnn_inputs, initial_state=init_state)\n",
    "    \n",
    "    with tf.variable_scope('softmax'):\n",
    "        W = tf.get_variable('W', [state_size, num_classes])\n",
    "        b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "    \n",
    "    # reshape rnn outputs and y so we can get the logits in a single matmul\n",
    "    rnn_outputs = tf.reshape(rnn_outputs, [-1, state_size])\n",
    "    y_reshaped = tf.reshape(y, [-1])\n",
    "    \n",
    "    logits = tf.matmul(rnn_outputs, W) + b\n",
    "    \n",
    "    predictions = tf.nn.softmax(logits)\n",
    "    \n",
    "    total_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "    \n",
    "    return dict(x = x, y = y, init_state = init_state, final_state = final_state,\n",
    "                total_loss = total_loss, train_step = train_step,\n",
    "                preds = predictions, saver = tf.train.Saver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/LSTM_20e_80s\n",
      "Failed to restore from checkpoint: checkpoints/LSTM_20e_80s, initializing variables instead\n",
      "avg training loss for epoch 0: 3.8802\n",
      "avg training loss for epoch 1: 3.6160\n",
      "avg training loss for epoch 2: 3.6106\n",
      "It took 265.3254716396332 seconds to build and train the RNN\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHT5JREFUeJzt3XuUlPWd5/H3ty80SEcaA3RYAYUAo4DY2IzRyLo2BoOO\nl2RjFCfu0RkmTEzk7GjwuK4GDDE7ydGYzcWoOxnPZOJKe4ujQzToaKvrBZGWmxBQxEREDRFEaYWm\nL9/9o57Gh7K7q6rr8lTV83mdU6erfs/vqfr2Q/H51fXb5u6IiEg8VERdgIiIFI5CX0QkRhT6IiIx\notAXEYkRhb6ISIwo9EVEYkShLyISIwp9EZEYUeiLiMRIVdQFJBsxYoQfffTRA97/ww8/ZOjQobkr\nKEdUV2ZUV2ZUV2bKsa7W1tZ33X1kyonuXlSnxsZGz0ZLS0tW++eL6sqM6sqM6spMOdYFrPY0MlYv\n74iIxIhCX0QkRhT6IiIxotAXEYkRhb6ISIwo9EVEYkShLyISI0X35ayBOtDZzY8e3cJk6466FBGR\nolU2j/TfeX8/d73wBj9f087+jq6oyxERKUplE/rjPn0YP7rgeF7/oJvrH9oYdTkiIkWpbEIf4Iyp\nn+HsCdU0v7idZaveiLocEZGiUzav6ff4r5Oqeb9yGEse3Mixow+nYWxd1CWJiBSNsnqkD1Bhxk/n\nzWDU4TV8885WdrW1R12SiEjRKLvQBxg+dBC3XdzIrg8PsHDZGjq79IkeEREo09AHmHbkMG740jSe\ne20XNz66JepyRESKQtmGPsBXZ47la58bx+1PbeORDW9HXY6ISOTKOvQBFp8zhYaxdSy6dx1bd+6N\nuhwRkUiVfejXVFVy68UnMGRQJX//61b27u+IuiQRkciUfegDjB42hJ9ddAJ/2PURV927nsRfFhMR\niZ9YhD7AyZ/9NNeceQy/2/gOtz21LepyREQiEZvQB5g/azxnTx/NjSs28+zWd6MuR0Sk4GIV+mbG\nD78ynYmjalm4bA079uyLuiQRkYKKVegDDK2p4raLG+no7OayO1vVkVNEYiV2oQ8wYWQtP7rgeNa/\n+b46copIrMQy9CHRkfNbTZ9VR04RiZXYhj7AlXP+gv88aQRLHtzI2u17oi5HRCTvYh36lRXqyCki\n8ZIy9M1ssJmtMrN1ZrbRzL7by5xxZtZiZmvMbL2ZnRWMH21m+8xsbXC6LR+/RDbUkVNE4iSdR/rt\nwGx3Px5oAOaa2UlJc64D7nH3GcA84Behba+5e0Nw+kZOqs4xdeQUkbhIGfqe0BZcrA5OyX0MHDg8\nOD8MeCtnFRaIOnKKSBxYOn1ozKwSaAUmAre4+9VJ20cDjwLDgaHAF9y91cyOBjYCrwAfANe5+//r\n5foXAAsA6uvrG5ubmwf8C7W1tVFbWzugfTu6nX98YT9vtXWz+OQh/Kfa3L3lkU1d+aS6MqO6MqO6\nMpNNXU1NTa3uPjPlRHdP+wTUAS3AtKTxK4FvB+dPBjaReBZRA3w6GG8EtgOH93cbjY2Nno2Wlpas\n9n9rz0fe+L1HvemmFv9g34Gsriss27ryRXVlRnVlRnVlJpu6gNWeRo5n9FDW3fcEoT83adN84J5g\nzvPAYGCEu7e7+65gvBV4DZicyW0W2uhhQ/j5X5/AH9WRU0TKUDqf3hlpZnXB+SHAHGBz0rQ3gNOD\nOceSCP0/B/tWBuMTgElA0be4PGmCOnKKSHmqSmPOaOBXQXhXkPiUznIzW0ri6cRDwLeBfzKzK0i8\nqXupu7uZnQosNbMOoBv4hrvvzs+vklvzZ41n7fY93LhiM9PHDOOUiSOiLklEJGspQ9/d1wMzehlf\nHDq/CTillzn3A/dnWWMkejpyvvKnvSxctoZ/XziLI+uGRF2WiEhWYv2N3FTUkVNEyo1CPwV15BSR\ncqLQT8MZUz/D5U0T1ZFTREqeQj9NV8yZzKmTR6ojp4iUNIV+miorjJ9c2KCOnCJS0hT6GVBHThEp\ndQr9DKkjp4iUMoX+AKgjp4iUKoX+AC0+ZwoNY+tYdO86tu7cG3U5IiJpUegPUE1VJbdefAJDBlWy\n4Net7N3fEXVJIiIpKfSzoI6cIlJqFPpZUkdOESklCv0cmD9rPGdPH82NKzbz7NZ3oy5HRKRPCv0c\n6OnIOXFULQuXrWHHnn1RlyQi0iuFfo6oI6eIlAKFfg6FO3IueVAdOUWk+Cj0c6ynI+fdq9WRU0SK\nj0I/D9SRU0SKlUI/D9SRU0SKlUI/T5I7cnZ164tbIhI9hX4ehTty3v+q2jSISPQU+nnW05Hz4dc7\n1JFTRCKn0C+AxedM4bPDKtSRU0Qip9AvgJqqSi6fUaOOnCISOYV+gQwfXKGOnCISOYV+Aakjp4hE\nTaFfYOrIKSJRShn6ZjbYzFaZ2Toz22hm3+1lzjgzazGzNWa23szOCm27xsy2mtkWM/tirn+BUqOO\nnCISpXQe6bcDs939eKABmGtmJyXNuQ64x91nAPOAXwCY2ZTg8lRgLvALM6vMVfGlSh05RSQqKUPf\nE9qCi9XBKfldSAcOD84PA94Kzp8HNLt7u7u/DmwFTsy66jKgjpwiEoW0XtM3s0ozWwvsBB5z9xeS\nplwPXGxmbwIPAwuD8SOB7aF5bwZjgjpyikjhWSYfHTSzOuABYKG7vxwavzK4rh+Z2cnAPwPTgJ8C\nK939zmDePwOPuPt9Sde7AFgAUF9f39jc3DzgX6itrY3a2toB758vfdXV7c7Nre1s3tXF//zcYCbU\nFfbVr1I7XlFTXZlRXZnJpq6mpqZWd5+ZcqK7Z3QCFgOLksY2AmNDl7cBo4BrgGtC4yuAk/u7/sbG\nRs9GS0tLVvvnS3917W5r91N+8Lif/L/+w9/du79wRXlpHq8oqa7MqK7MZFMXsNrTyPB0Pr0zMniE\nj5kNAeYAm5OmvQGcHsw5FhgM/Bl4CJhnZjVmNh6YBKxKuRLFTHJHzs6u7qhLEpEylc5r+qOBFjNb\nD7xI4jX95Wa21MzODeZ8G/i6ma0DlgGXBovPRuAeYBPwO+Bb7q6PqvQi3JHzxke3RF2OiJSpqlQT\n3H09MKOX8cWh85uAU/rY//vA97OoMTa+OnMsa7fv4fanttEwpo4zjxsddUkiUmb0jdwis/icKcwY\nV6eOnCKSFwr9IlNTVcmtX2tUR04RyQuFfhH6zLDB6sgpInmh0C9S6sgpIvmg0C9i6sgpIrmm0C9i\n4Y6cl9/1Em++91HUJYlIiVPoF7mejpydXc5ld76kjpwikhWFfgmYMLKWmy9sYMMOdeQUkewo9EvE\nnCn16sgpIllT6JeQK+ZM5tTJI1ny4EbWbt8TdTkiUoIU+iWkssL4yYUNjDq8hm/e2cqutvaoSxKR\nEqPQLzHqyCki2VDolyB15BSRgVLol6ivzhzLxSeN4/antvHwhrejLkdESoRCv4QtPnsqM8bVcZU6\ncopImhT6JWxQVYU6copIRhT6JU4dOUUkEwr9MqCOnCKSLoV+mVBHThFJh0K/TKgjp4ikQ6FfRtSR\nU0RSUeiXGXXkFJH+KPTLkDpyikhfFPplSh05RaQ3Cv0ypY6cItIbhX4ZU0dOEUmm0C9z044cxve/\nfFyiI+cKdeQUiTuFfgyc3zgm0ZHzaXXkFIm7qlQTzGww8DRQE8y/z92XJM35MdAUXDwMGOXudcG2\nLmBDsO0Ndz83R7VLBhafPZWNb33AVfeuY3J9LRNHfSrqkkQkAuk80m8HZrv78UADMNfMTgpPcPcr\n3L3B3RuAnwG/CW3e17NNgR8ddeQUEUgj9D2hLbhYHZz6a+V4EbAsB7VJjqkjp4ik9Zq+mVWa2Vpg\nJ/CYu7/Qx7yjgPHAE6HhwWa22sxWmtmXsq5YsqKOnCLxZpk82jOzOuABYKG7v9zL9quBMe6+MDR2\npLvvMLMJJBaD0939taT9FgALAOrr6xubm5sH9MsAtLW1UVtbO+D986WY6nJ3bl3XzovvdPGtac7M\nMcVRV1gxHa8w1ZUZ1ZWZbOpqampqdfeZKSe6e0YnYDGwqI9ta4DP97PvvwDn93f9jY2Nno2Wlpas\n9s+XYqurbX+Hz7n5SZ963XLfvvvDqMv5hGI7Xj1UV2ZUV2ayqQtY7WlkeMqXd8xsZPAIHzMbAswB\nNvcy7xhgOPB8aGy4mdUE50cApwCbUq5EkndDa6q4/b/NpMtRR06RGEnnNf3RQIuZrQdeJPGa/nIz\nW2pm4U/jzAOagxWnx7HAajNbB7QAP3B3hX6RGD9iKAum16gjp0iMpPycvruvB2b0Mr446fL1vcx5\nDjgui/okz2aMquLyprH8vGUrDePquOjEcVGXJCJ5pG/kijpyisSIQl/UkVMkRhT6Aqgjp0hcKPTl\nIHXkFCl/Cn05hDpyipQ3hb58wuKzpzJjXB1X3buOrTv3Rl2OiOSQQl8+QR05RcqXQl96pY6cIuVJ\noS99UkdOkfKj0Jd+zZ81nrOnj+bGFZt55tV3oy5HRLKk0Jd+mRk//Mp0Jo6qZeGyl3jzvY+iLklE\nsqDQl5R6OnJ2drk6coqUOIW+pGX8iKHcfGGDOnKKlDiFvqRtzpR6Lm+ayN2rt7Ns1RtRlyMiA6DQ\nl4yoI6dIaVPoS0bCHTkvu7OVd9WRU6SkKPQlYz0dOXd/eICFd6kjp0gpUejLgPR05Hx+mzpyipQS\nhb4MmDpyipQehb5kRR05RUqLQl+yoo6cIqVFoS9ZU0dOkdKh0JecUEdOkdKg0JecUUdOkeKn0Jec\nUUdOkeKn0JecUkdOkeKm0JecU0dOkeKl0Je8UEdOkeKUMvTNbLCZrTKzdWa20cy+28ucH5vZ2uD0\nipntCW27xMxeDU6X5PoXkOKljpwixSedR/rtwGx3Px5oAOaa2UnhCe5+hbs3uHsD8DPgNwBmdgSw\nBPgccCKwxMyG5/IXkOKljpwixSdl6HtCW3CxOjj19+2bi4BlwfkvAo+5+253fw94DJibRb1SYtSR\nU6S4WDrfnjSzSqAVmAjc4u5X9zHvKGAlMMbdu8xsETDY3W8Itn8H2OfuNyXttwBYAFBfX9/Y3Nw8\n4F+ora2N2traAe+fL3Gv65kdHfxywwHOHF/NhX8xqGjqypTqyozqykw2dTU1NbW6+8yUE9097RNQ\nB7QA0/rYfjXws9DlRcB1ocvfARb1dxuNjY2ejZaWlqz2zxfV5X7tA+v9qKuX+2/Xv5Vyro5XZlRX\nZsqxLmC1p5HjGX16x933BKHf10s08/j4pR2AHcDY0OUxwZjEkDpyikQvnU/vjDSzuuD8EGAOsLmX\neccAw4HnQ8MrgDPMbHjwBu4ZwZjEkDpyikQvnUf6o4EWM1sPvEjijdnlZrbUzM4NzZsHNAdPMwBw\n993A94L9XgSWBmMSU+rIKRKtqlQT3H09MKOX8cVJl6/vY/87gDsGWJ+UoZ6OnDf89vfc9tQ2Ljvt\ns1GXJBIb+kauREIdOUWiodCXSKgjp0g0FPoSGXXkFCk8hb5ESh05RQpLoS+RU0dOkcJJ+ekdkUK4\nYs5k1geP9o8dfXjU5YiULT3Sl6KQ3JHzg3Z9fl8kHxT6UjTCHTlvXbdfHTlF8kChL0Vl2pHD+P6X\nj+P3u7u5ccWWqMsRKTsKfSk65zeOYfbYKm5/ehsPb3g76nJEyopCX4rSXx87SB05RfJAoS9FqarC\n1JFTJA8U+lK0wh05F927Th05RXJAoS9Fracj54qNf+LWp16LuhyRkqfQl6LX05HzphVb1JFTJEsK\nfSl66sgpkjsKfSkJ6sgpkhsKfSkZ6sgpkj2FvpQUdeQUyY5CX0rOFXMmc+rkkSx5cCNrt++JuhyR\nkqLQl5JTWWH8dN7HHTnfbWuPuiSRkqHQl5JUd9jHHTkX3rVGHTlF0qTQl5LV05Hz+W271JFTJE0K\nfSlp5zeO4eKTxqkjp0iaFPpS8hafPVUdOUXSpNCXkjeoqkIdOUXSpNCXsqCOnCLpSRn6ZjbYzFaZ\n2Toz22hm3+1j3gVmtimYc1dovMvM1ganh3JZvEiYOnKKpFaVxpx2YLa7t5lZNfCMmT3i7it7JpjZ\nJOAa4BR3f8/MRoX23+fuDbktW6R382eNZ+32Pdy0YgvTj6xj1qQRUZckUlRSPtL3hLbgYnVwSn7u\n/HXgFnd/L9hnZ06rFEmTOnKK9C+t1/TNrNLM1gI7gcfc/YWkKZOByWb2rJmtNLO5oW2DzWx1MP6l\nHNUt0id15BTpm2XyhpeZ1QEPAAvd/eXQ+HKgA7gAGAM8DRzn7nvM7Eh332FmE4AngNPd/bWk610A\nLACor69vbG5uHvAv1NbWRm1t7YD3zxfVlZlc1LVmZyc/eamdU8dU8bfTaoqmrnxQXZkpx7qamppa\n3X1myonuntEJWAwsShq7Dfib0OXHgb/sZd9/Ac7v7/obGxs9Gy0tLVntny+qKzO5quvG3232o65e\n7ne98MecXF+5H69cU12ZyaYuYLWnkeHpfHpnZPAIHzMbAswBNidN+zfgtGDOCBIv92wzs+FmVhMa\nPwXYlHIlEskRdeQUOVQ6r+mPBlrMbD3wIonX9Jeb2VIzOzeYswLYZWabgBbgKnffBRwLrDazdcH4\nD9xdoS8Fo46cIodK+ZFNd18PzOhlfHHovANXBqfwnOeA47IvU2TgejpyfuXW51h41xp+Pf9Eqir1\nvUSJJ93zJRbUkVMkQaEvsaGOnCIKfYkZdeSUuFPoS6yoI6fEnUJfYkcdOSXOFPoSS+rIKXGl0JfY\nmj9rPGdPH81NK7bwzKvvRl2OSEEo9CW21JFT4kihL7GmjpwSNwp9ib3xI4Zy84UNbNjxPkse3Bh1\nOSJ5pdAXAeZMqWfh7IncvXo7y1a9EXU5Inmj0BcJ/MMX1JFTyp9CXySgjpwSBwp9kZCejpy7PzzA\nwrvW0NnVHXVJIjml0BdJoo6cUs4U+iK9UEdOKVcKfZE+qCOnlCOFvkgf1JFTypFCX6Qf6sgp5Sbl\n38gVibuejpw3/Pb3bPiDMWrTswyqrGBQVXCqrKA6+Jm4bKFtlVRXGYMqK6ipqqC6l/1qgrHkbeGf\n1ZUVVFcaZhb14ZASp9AXScP8WePZ39HF42tf41NDqjnQ2cW+ji7e39fBgc5uDnR1H/KzI/jZ2Z3b\nZwa9LwjGgf37OGLjsx8vOEkLycEFJ7SwVAcL0aBetiXPG5R8PVUf3/agygotRiVEoS+SBjPj8tmT\nmFaxg9NOOzHt/bq6PbEA9CwKnR8vCu3BItHRmbQ9tIB8cpsHP7vo6PSD2976034OH1LNgc5u9nd0\ns3d/58F92nsWodCC1NGV48UotACFF4uO/fs44uVnsnqGc+g2Y1Bl5SG3VZP0jCq8UFVUaDFKptAX\nyaPKCqOyopLB1ZV5vZ0nn3wyo8WouztYMJIWloOL0cHFyTnQ1XXogtPZzYHOrmBbaFFJXtS6unnr\nnf0MGzro4Hhbe2evz4gOLnI5Xox6nolUJy0oB/Z/xBEvP5PY1seiUx1aYA552S7p+g559hPadsiz\nqPD1R7wYKfRFYqiiwhhchIuRu4cWhNAi09XFgU7/xGLR27OlQxauPp5JvfXOfg4fOujg9Xz0UWcv\nz4j8kH1yqarCDl0Qgp+jqvZz2mk5valP3nZ+r15EJH1mRk1VJTVVxbcY9Tyz+cSik7RY9PZSXqpt\n7cEi43sP5PG3TlDoi4ikYGaJ9xOqKqAmf7fz5JNP5u/KA/qcvohIjCj0RURiJGXom9lgM1tlZuvM\nbKOZfbePeReY2aZgzl2h8UvM7NXgdEkuixcRkcyk85p+OzDb3dvMrBp4xswecfeVPRPMbBJwDXCK\nu79nZqOC8SOAJcBMwIFWM3vI3d/L+W8iIiIppXyk7wltwcXq4JT8YdqvA7f0hLm77wzGvwg85u67\ng22PAXNzUrmIiGQsrdf0zazSzNYCO0mE+AtJUyYDk83sWTNbaWY9wX4ksD00781gTEREImCZdA00\nszrgAWChu78cGl8OdAAXAGOAp4HjgL8DBrv7DcG87wD73P2mpOtdACwAqK+vb2xubh7wL9TW1kZt\nbe2A988X1ZUZ1ZUZ1ZWZcqyrqamp1d1nppzo7hmdgMXAoqSx24C/CV1+HPhL4CLg9tD47cBF/V1/\nY2OjZ6OlpSWr/fNFdWVGdWVGdWWmHOsCVnsaGZ7ykb6ZjQQ63H2PmQ0BHgV+6O7LQ3PmBmF+iZmN\nANYADQRv3gInBFNfAhrdfXc/t/dn4I8pV6u+jQDezWL/fFFdmVFdmVFdmSnHuo5y95GpJqXz6Z3R\nwK/MrJLEewD3uPtyM1tKYmV5CFgBnGFmm4Au4Cp33wVgZt8DXgyua2l/gQ+QTtH9MbPVns5TnAJT\nXZlRXZlRXZmJc10pQ9/d1wMzehlfHDrvwJXBKXneHcAd2ZUpIiK5oG/kiojESDmG/v+JuoA+qK7M\nqK7MqK7MxLaujD6yKSIipa0cH+mLiEgfSib0zWyumW0xs61m9j962V5jZncH218ws6ND264JxreY\n2RcLXNeVQSO69Wb2uJkdFdrWZWZrg9NDBa7rUjP7c+j2/y60LW9N8tKo68ehml4xsz2hbfk8XneY\n2U4ze7mP7WZmPw3qXm9mJ4S25fN4parra0E9G8zsOTM7PrTtD8H4WjNbXeC6TjOz90P/XotD2/q9\nD+S5rqtCNb0c3KeOCLbl83iNNbMW+7gp5X/vZU5h7mPpfJg/6hNQCbwGTAAGAeuAKUlzvgncFpyf\nB9wdnJ8SzK8BxgfXU1nAupqAw4Lzl/XUFVxui/B4XQr8vJd9jwC2BT+HB+eHF6qupPkLgTvyfbyC\n6z6VxPdJXu5j+1nAI4ABJwEv5Pt4pVnX53tuDzizp67g8h+AEREdr9OA5dneB3JdV9Lcc4AnCnS8\nRgMnBOc/BbzSy//JgtzHSuWR/onAVnff5u4HgGbgvKQ55wG/Cs7fB5xuZhaMN7t7u7u/DmwNrq8g\ndbl7i7t/FFxcSaJNRb6lc7z6ks8meZnWdRGwLEe33S93fxro7zsk5wH/6gkrgTozG02emwqmqsvd\nn/OPu9YW6v6VzvHqSzb3zVzXVcj719vu/lJwfi/wez7Zh6wg97FSCf10GrcdnOPuncD7wKfT3Def\ndYXNJ7GS9xhsZqst0aTuSzmqKZO6vhI8jbzPzMZmuG8+6yJ4GWw88ERoOF/HKx191V5MTQWT718O\nPGpmrZbob1VoJ1vi73A8YmZTg7GiOF5mdhiJ4Lw/NFyQ42WJl55nAMmNKwtyH9PfyC0QM7uYxN8V\n+C+h4aPcfYeZTQCeMLMN7v5agUr6d2CZu7eb2d+TeJY0u0C3nY55wH3u3hUai/J4FTUzayIR+rNC\nw7OC4zUKeMzMNgePhAvhJRL/Xm1mdhbwb8CkAt12Os4BnvVDOwTk/XiZWS2JheYf3P2DXF53ukrl\nkf4OYGzo8phgrNc5ZlYFDAN2pblvPuvCzL4AXAuc6+7tPePuviP4uQ14kl6++Zyvutx9V6iWXwKN\n6e6bz7pC5pH01DuPxysdfdWez+OVFjObTuLf8DwP2p/AIcdrJ4nuuLl6WTMld//Ag7/D4e4PA9WW\n6MsV+fEK9Hf/ysvxssQfobof+L/u/ptephTmPpaPNy1yfSLxjGQbiaf7PW/+TE2a8y0OfSP3nuD8\nVA59I3cbuXsjN526ZpB442pS0vhwoCY4PwJ4lRy9oZVmXaND578MrPSP3zR6PahveHD+iELVFcw7\nhsSbalaI4xW6jaPp+43Jv+LQN9lW5ft4pVnXOBLvU30+aXwo8KnQ+eeAuQWs6zM9/34kwvON4Nil\ndR/IV13B9mEkXvcfWqjjFfzu/wr8737mFOQ+lrMDne8TiXe2XyERoNcGY0tJPHoGGAzcG/wHWAVM\nCO17bbDfFuDMAtf1H8CfgLXB6aFg/PPAhuBOvwGYX+C6/hHYGNx+C3BMaN+/DY7jVkItswtRV3D5\neuAHSfvl+3gtA94m8Xch3iTxUsk3gG8E2w24Jah7AzCzQMcrVV2/BN4L3b9WB+MTgmO1Lvh3vrbA\ndV0eun+tJLQo9XYfKFRdwZxLSXy4I7xfvo/XLBLvGawP/VudFcV9TN/IFRGJkVJ5TV9ERHJAoS8i\nEiMKfRGRGFHoi4jEiEJfRCRGFPoiIjGi0BcRiRGFvohIjPx/pCjsCWUo+5EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f54a0723438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = time.time()\n",
    "g = build_multilayer_lstm_graph_with_dynamic_rnn(num_steps=80)\n",
    "losses = train_network(g, num_epochs=3, num_steps=80, save='checkpoints/LSTM_20e_80s')\n",
    "print('It took {} seconds to build and train the RNN'.format(time.time() - t))\n",
    "plt.plot(losses)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_characters(g, checkpoint, num_chars, prompt='A', pick_top_chars=None):\n",
    "    with tf.Session() as sess:\n",
    "        g['saver'].restore(sess, checkpoint)\n",
    "        \n",
    "        state = None\n",
    "        current_char = vocab_to_idx[prompt]\n",
    "        chars = [current_char]\n",
    "        \n",
    "        for i in range(num_chars):\n",
    "            feed_dict = {g['x']: [[current_char]]}\n",
    "\n",
    "            if state is not None:\n",
    "                feed_dict[g['init_state']] = state\n",
    "            \n",
    "            preds, state = sess.run([g['preds'], g['final_state']], feed_dict)\n",
    "            \n",
    "            p = np.squeeze(preds)\n",
    "\n",
    "            if pick_top_chars is not None:\n",
    "                p[np.argsort(p)[:-pick_top_chars]] = 0\n",
    "                p = p / np.sum(p)\n",
    "\n",
    "            current_char = np.random.choice(vocab_size, 1, p=p)[0]\n",
    "            \n",
    "            chars.append(current_char)\n",
    "\n",
    "    chars = map(lambda x: idx_to_vocab[x], chars)\n",
    "    return \"\".join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/LSTM_20e_80s\n",
      "Aшнпе  аееа\n",
      " еа  \n",
      "\n",
      " о\n",
      "аее ее  о\n",
      "  а\n",
      "\n",
      " аоо оое\n",
      " \n",
      "о\n",
      "а   аа\n",
      " \n",
      "еа  оа а а о е\n",
      "а е е\n",
      "о еоо\n",
      "\n",
      "о \n",
      " о о \n",
      "\n",
      "аоое \n",
      "ее   ае\n",
      "\n",
      " а  а\n",
      "ооаааео\n",
      "ое \n"
     ]
    }
   ],
   "source": [
    "g = build_multilayer_lstm_graph_with_dynamic_rnn(num_steps=1, batch_size=1)\n",
    "print(generate_characters(g, 'checkpoints/LSTM_20e_80s', 128, prompt='A', pick_top_chars=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

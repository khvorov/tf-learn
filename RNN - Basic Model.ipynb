{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# based on tutorial:\n",
    "# http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected cross entropy loss if the model:\n",
      "- learns neither dependency: 0.661563238158\n",
      "- learns first dependency:   0.519166699707\n",
      "- learns both dependencies:  0.454454367449\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected cross entropy loss if the model:\")\n",
    "print(\"- learns neither dependency:\", -(0.625 * np.log(0.625) +\n",
    "                                      0.375 * np.log(0.375)))\n",
    "# Learns first dependency only ==> 0.51916669970720941\n",
    "print(\"- learns first dependency:  \",\n",
    "      -0.5 * (0.875 * np.log(0.875) + 0.125 * np.log(0.125))\n",
    "      -0.5 * (0.625 * np.log(0.625) + 0.375 * np.log(0.375)))\n",
    "print(\"- learns both dependencies: \", -0.50 * (0.75 * np.log(0.75) + 0.25 * np.log(0.25))\n",
    "      - 0.25 * (2 * 0.50 * np.log (0.50)) - 0.25 * (0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_steps = 5 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        p = 0.5\n",
    "        if X[i - 3] == 1:\n",
    "            p += 0.5\n",
    "        if X[i - 8] == 1:\n",
    "            p -= 0.25\n",
    "        Y.append(0 if np.random.rand() > p else 1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "    \n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    \n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "# RNN inputs\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of rnn_cell\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding rnn_cells to the graph\n",
    "state = init_state\n",
    "rnn_outputs = []\n",
    "\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions, loss and training step\n",
    "\n",
    "# logits and prediction\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "# losses and train step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit)\n",
    "          for logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate=learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "def train_network(num_epochs, num_steps, state_size, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        \n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "            if verbose:\n",
    "                print('\\nEPOCH', idx)\n",
    "\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses, total_loss, final_state, train_step],\n",
    "                             feed_dict = {x: X, y: Y, init_state: training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print('average loss at step ', step, training_loss / 100)\n",
    "                    training_losses.append(training_loss / 100)\n",
    "                    training_loss = 0\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "average loss at step  100 0.651783311963\n",
      "average loss at step  200 0.602998964787\n",
      "average loss at step  300 0.555260771513\n",
      "average loss at step  400 0.526330669522\n",
      "average loss at step  500 0.521798354089\n",
      "average loss at step  600 0.520632512271\n",
      "average loss at step  700 0.519455341101\n",
      "average loss at step  800 0.520941150188\n",
      "average loss at step  900 0.520038294196\n",
      "\n",
      "EPOCH 1\n",
      "average loss at step  100 0.526802845001\n",
      "average loss at step  200 0.518486346602\n",
      "average loss at step  300 0.519092451036\n",
      "average loss at step  400 0.520385197699\n",
      "average loss at step  500 0.520486237705\n",
      "average loss at step  600 0.520521895289\n",
      "average loss at step  700 0.520220109224\n",
      "average loss at step  800 0.520726292431\n",
      "average loss at step  900 0.521282426417\n",
      "\n",
      "EPOCH 2\n",
      "average loss at step  100 0.527849881351\n",
      "average loss at step  200 0.516263147891\n",
      "average loss at step  300 0.519829786718\n",
      "average loss at step  400 0.517850238979\n",
      "average loss at step  500 0.517693577111\n",
      "average loss at step  600 0.519030721188\n",
      "average loss at step  700 0.519764611721\n",
      "average loss at step  800 0.519897292256\n",
      "average loss at step  900 0.517814011574\n",
      "\n",
      "EPOCH 3\n",
      "average loss at step  100 0.524597786665\n",
      "average loss at step  200 0.517479459047\n",
      "average loss at step  300 0.520726729035\n",
      "average loss at step  400 0.520294210911\n",
      "average loss at step  500 0.516941947937\n",
      "average loss at step  600 0.518809148371\n",
      "average loss at step  700 0.520082290471\n",
      "average loss at step  800 0.518244689107\n",
      "average loss at step  900 0.519182062447\n",
      "\n",
      "EPOCH 4\n",
      "average loss at step  100 0.524718093872\n",
      "average loss at step  200 0.520065229833\n",
      "average loss at step  300 0.522047607303\n",
      "average loss at step  400 0.519022834003\n",
      "average loss at step  500 0.521168935895\n",
      "average loss at step  600 0.519371281266\n",
      "average loss at step  700 0.51978209883\n",
      "average loss at step  800 0.520073744059\n",
      "average loss at step  900 0.518754273951\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPa8JmlJr3Q8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fddf205cf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(num_epochs=5, num_steps=num_steps, state_size=state_size)\n",
    "plt.plot(training_losses)\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

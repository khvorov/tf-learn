{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# based on tutorial:\n",
    "# http://r2rt.com/recurrent-neural-networks-in-tensorflow-i.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected cross entropy loss if the model:\n",
      "- learns neither dependency: 0.661563238158\n",
      "- learns first dependency:   0.519166699707\n",
      "- learns both dependencies:  0.454454367449\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected cross entropy loss if the model:\")\n",
    "print(\"- learns neither dependency:\", -(0.625 * np.log(0.625) +\n",
    "                                      0.375 * np.log(0.375)))\n",
    "# Learns first dependency only ==> 0.51916669970720941\n",
    "print(\"- learns first dependency:  \",\n",
    "      -0.5 * (0.875 * np.log(0.875) + 0.125 * np.log(0.125))\n",
    "      -0.5 * (0.625 * np.log(0.625) + 0.375 * np.log(0.375)))\n",
    "print(\"- learns both dependencies: \", -0.50 * (0.75 * np.log(0.75) + 0.25 * np.log(0.25))\n",
    "      - 0.25 * (2 * 0.50 * np.log (0.50)) - 0.25 * (0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_steps = 5 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = np.zeros(size, dtype=np.int32)\n",
    "    rands = np.random.rand(size) # consumes more memory, but much faster than calling rand() on every step\n",
    "    for i in range(size):\n",
    "        p = 0.5\n",
    "        if X[i - 3] == 1:\n",
    "            p += 0.5\n",
    "        if X[i - 8] == 1:\n",
    "            p -= 0.25\n",
    "        Y[i] = 0 if rands[i] > p else 1\n",
    "    return X, np.array(Y)\n",
    "\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "    \n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    \n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "    \n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Placeholders\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name='input_placeholder')\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name='labels_placeholder')\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "# RNN inputs\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of rnn_cell\n",
    "with tf.variable_scope('rnn_cell'):\n",
    "    W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope('rnn_cell', reuse=True):\n",
    "        W = tf.get_variable('W', [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable('b', [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding rnn_cells to the graph\n",
    "state = init_state\n",
    "rnn_outputs = []\n",
    "\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions, loss and training step\n",
    "\n",
    "# logits and prediction\n",
    "with tf.variable_scope('softmax'):\n",
    "    W = tf.get_variable('W', [state_size, num_classes])\n",
    "    b = tf.get_variable('b', [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "# losses and train step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit)\n",
    "          for logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate=learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "def train_network(num_epochs, num_steps, state_size, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        \n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "\n",
    "            if verbose:\n",
    "                print('\\nEPOCH', idx)\n",
    "\n",
    "            for step, (X, Y) in enumerate(epoch):\n",
    "                None\n",
    "                tr_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses, total_loss, final_state, train_step],\n",
    "                             feed_dict = {x: X, y: Y, init_state: training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print('average loss at step ', step, training_loss / 100)\n",
    "                    training_losses.append(training_loss / 100)\n",
    "                    training_loss = 0\n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EPOCH 0\n",
      "average loss at step  100 0.653878762126\n",
      "average loss at step  200 0.586378536224\n",
      "average loss at step  300 0.543813028932\n",
      "average loss at step  400 0.531112838387\n",
      "average loss at step  500 0.526943523586\n",
      "average loss at step  600 0.52677296102\n",
      "average loss at step  700 0.523575408161\n",
      "average loss at step  800 0.521047199667\n",
      "average loss at step  900 0.524018545151\n",
      "\n",
      "EPOCH 1\n",
      "average loss at step  100 0.529598869681\n",
      "average loss at step  200 0.520378084183\n",
      "average loss at step  300 0.521988299489\n",
      "average loss at step  400 0.523168939054\n",
      "average loss at step  500 0.518881621063\n",
      "average loss at step  600 0.521824620068\n",
      "average loss at step  700 0.521147457063\n",
      "average loss at step  800 0.519658360481\n",
      "average loss at step  900 0.519277474582\n",
      "\n",
      "EPOCH 2\n",
      "average loss at step  100 0.526448368132\n",
      "average loss at step  200 0.519297617972\n",
      "average loss at step  300 0.522672440112\n",
      "average loss at step  400 0.521988379657\n",
      "average loss at step  500 0.520174096227\n",
      "average loss at step  600 0.520836962163\n",
      "average loss at step  700 0.521995194256\n",
      "average loss at step  800 0.520339433551\n",
      "average loss at step  900 0.517699332535\n",
      "\n",
      "EPOCH 3\n",
      "average loss at step  100 0.526967580616\n",
      "average loss at step  200 0.516926855445\n",
      "average loss at step  300 0.521757462323\n",
      "average loss at step  400 0.521346868575\n",
      "average loss at step  500 0.517426534891\n",
      "average loss at step  600 0.520509130657\n",
      "average loss at step  700 0.519090006649\n",
      "average loss at step  800 0.520828618407\n",
      "average loss at step  900 0.522264840603\n",
      "\n",
      "EPOCH 4\n",
      "average loss at step  100 0.525782549381\n",
      "average loss at step  200 0.520181083977\n",
      "average loss at step  300 0.519345658422\n",
      "average loss at step  400 0.52212571919\n",
      "average loss at step  500 0.516840658486\n",
      "average loss at step  600 0.521007380784\n",
      "average loss at step  700 0.51985645026\n",
      "average loss at step  800 0.520539525151\n",
      "average loss at step  900 0.520818245411\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhb4xxniIhb4xxniIhb4xxnjI/wdR52m2+m1ytAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2fdc73cb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(num_epochs=5, num_steps=num_steps, state_size=state_size)\n",
    "plt.plot(training_losses)\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
